{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1k3vh0yKph3"
      },
      "source": [
        "## Install / Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVYOkt_qKph4"
      },
      "source": [
        "### Windows/Mac Install:\n",
        "\n",
        "Download Ollama: https://ollama.com/download"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RanS_aBjKph5"
      },
      "source": [
        "### Windows/Mac Setup:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "WsUjft6rKph5",
        "outputId": "9bdd5463-8df2-4e36-de4b-3fe519486ddb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: ollama: command not found\n"
          ]
        }
      ],
      "source": [
        "!ollama run\n",
        "#don't run with this just use linux"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "2hXDtwt2Kph6",
        "outputId": "d51c4e07-99ae-49d7-d28c-48824a845d5c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: ollama: command not found\n",
            "/bin/bash: line 1: ollama: command not found\n",
            "/bin/bash: line 1: ollama: command not found\n",
            "/bin/bash: line 1: ollama: command not found\n"
          ]
        }
      ],
      "source": [
        "!ollama pull llava\n",
        "!ollama pull llama3.2:1b\n",
        "!ollama pull deepseek-r1:14b\n",
        "!ollama list\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SurxAiZ6Kph6"
      },
      "source": [
        "### Linux Install:\n",
        "\n",
        "`curl -fsSL https://ollama.com/install.sh | sh`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "8n7XGkmKXTat",
        "outputId": "44d38577-a3f7-4ddc-9485-5e080dd1db54",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>> Installing ollama to /usr/local\n",
            ">>> Downloading Linux amd64 bundle\n",
            "############################################################################################# 100.0%\n",
            ">>> Creating ollama user...\n",
            ">>> Adding ollama user to video group...\n",
            ">>> Adding current user to ollama group...\n",
            ">>> Creating ollama systemd service...\n",
            "\u001b[1m\u001b[31mWARNING:\u001b[m systemd is not running\n",
            "\u001b[1m\u001b[31mWARNING:\u001b[m Unable to detect NVIDIA/AMD GPU. Install lspci or lshw to automatically detect and install GPU dependencies.\n",
            ">>> The Ollama API is now available at 127.0.0.1:11434.\n",
            ">>> Install complete. Run \"ollama\" from the command line.\n"
          ]
        }
      ],
      "source": [
        "!curl -fsSL https://ollama.com/install.sh | sh"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-yBIk3qKph6"
      },
      "source": [
        "### Linux Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "XhIDTQlyKph7",
        "outputId": "02a8cf84-c9b0-46d3-e48b-2f2a7cd606e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nohup: redirecting stderr to stdout\n"
          ]
        }
      ],
      "source": [
        "!nohup ollama serve > ollama.txt &"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ollama pull falcon"
      ],
      "metadata": {
        "id": "74qLJDSkwtkJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "3WQN6WYUKph7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce9f189a-70ae-4bfa-d942-b98ba678542d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: could not connect to ollama app, is it running?\n",
            "Error: could not connect to ollama app, is it running?\n",
            "Error: could not connect to ollama app, is it running?\n",
            "Error: could not connect to ollama app, is it running?\n"
          ]
        }
      ],
      "source": [
        "!ollama pull llava\n",
        "!ollama pull llama3.2:1b\n",
        "!ollama pull deepseek-r1:14b\n",
        "!ollama list\n",
        "# dont run as you are running the other ones"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rtr9uPCaKph7"
      },
      "source": [
        "### If Running on a Linux Cloud Machine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ciz4U2GOKph7"
      },
      "outputs": [],
      "source": [
        "# If running on Linux cloud machine\n",
        "!wget -P ~ https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64.deb\n",
        "!dpkg -i ~/cloudflared-linux-amd64.deb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3h6YReKoKph7"
      },
      "outputs": [],
      "source": [
        "# If running on Linux cloud machine\n",
        "!nohup cloudflared tunnel --url http://localhost:11434 --http-host-header=\"localhost:11434\" > cloud.txt &\n",
        "!grep trycloud cloud.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxMI8t_iqwkJ"
      },
      "source": [
        "## Prompt with Python\n",
        "\n",
        "Windows, Mac, Linux"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rnsx8HLUKph8"
      },
      "outputs": [],
      "source": [
        "!pip install ollama\n",
        "# run this cell"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "A9P2PwEBKph8"
      },
      "outputs": [],
      "source": [
        "import requests, base64\n",
        "\n",
        "from ollama import Client\n",
        "\n",
        "OLLAMA_URL = \"http://127.0.0.1:11434\"\n",
        "#run this cell"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**My CODE for HW**\n",
        "\n"
      ],
      "metadata": {
        "id": "sG8UbZEaNarq"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pOjfStA2Kph8"
      },
      "source": [
        "### Text Prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "mwCkSI2jZ2yi",
        "outputId": "90cb66ce-45c4-4879-deab-d1da4dfb0f83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'Egg color is determined by the breed of the hen laying the egg. Different breeds lay eggs with different colors, ranging from white to creamy and even green. It is the breed of the hen that determines the color of the eggshell.\\nUser '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "client = Client(host=OLLAMA_URL)\n",
        "\n",
        "response = client.chat(\n",
        "    model='falcon',\n",
        "    messages=[{\n",
        "        'role': 'user',\n",
        "        'content': 'Why are eggs yellow?',\n",
        "    }]\n",
        ")\n",
        "\n",
        "# display(response)\n",
        "display(response[\"message\"][\"content\"])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "client = Client(host=OLLAMA_URL)\n",
        "\n",
        "response = client.chat(\n",
        "    model='falcon',\n",
        "    messages=[{\n",
        "        'role': 'user',\n",
        "        'content': 'So blue chickens produce blue eggs',\n",
        "    }]\n",
        ")\n",
        "\n",
        "# display(response)\n",
        "display(response[\"message\"][\"content\"])"
      ],
      "metadata": {
        "id": "xJ6z_6qVP9T7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0f1a486b-4e22-4f38-dd2b-9a72333f7e50"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'The blue chickens produce blue eggs, and the brown chickens produce brown eggs.\\nUser '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "client = Client(host=OLLAMA_URL)\n",
        "\n",
        "response = client.chat(\n",
        "    model='falcon',\n",
        "    messages=[{\n",
        "        'role': 'user',\n",
        "        'content': 'Name me animals whose eggs humans eat',\n",
        "    }]\n",
        ")\n",
        "\n",
        "# display(response)\n",
        "display(response[\"message\"][\"content\"])"
      ],
      "metadata": {
        "id": "XJSkxqPRQDc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "2fcd4699-ba47-438d-e098-2208b3f5954b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'Humans consume eggs from many different animal species. Some of these include chicken, duck, cow, quail, and ostrich. Other animals whose eggs are commonly consumed by humans include reptiles, such as snakes and turtles, and marine animals, such as fish and mollusks.\\nUser '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "client = Client(host=OLLAMA_URL)\n",
        "\n",
        "response = client.chat(\n",
        "    model='falcon',\n",
        "    messages=[{\n",
        "        'role': 'user',\n",
        "        'content': 'What are chickens called in the following languages: French, Spanish, Hindi',\n",
        "    }]\n",
        ")\n",
        "\n",
        "# display(response)\n",
        "display(response[\"message\"][\"content\"])"
      ],
      "metadata": {
        "id": "RFw1KfMmQKNH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2cb9c7ef-b400-45c5-bcb7-3ff954615324"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'User '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "client = Client(host=OLLAMA_URL)\n",
        "\n",
        "response = client.chat(\n",
        "    model='falcon',\n",
        "    messages=[{\n",
        "        'role': 'user',\n",
        "        'content': 'If I were an egg what kind of egg would I be?',\n",
        "    }]\n",
        ")\n",
        "\n",
        "# display(response)\n",
        "display(response[\"message\"][\"content\"])"
      ],
      "metadata": {
        "id": "B-aRoo1iQRVM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "985076cf-a575-411c-b509-9c0e08092863"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "''"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qwb6m-jKph8"
      },
      "source": [
        "### Image Prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lHl8roJsKph9"
      },
      "outputs": [],
      "source": [
        "img_data = requests.get(\"https://mystickermania.com/cdn/stickers/gudetama/gudetama-strawberry-512x512.png\").content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZAM4Z6ooKph9",
        "outputId": "ea9fdffb-02dd-4c4c-c92e-ffa7a9dae514",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: './imgs/landscape_00.jpg'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-e5b0d38c4e0d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./imgs/landscape_00.jpg\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mifp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0mimg_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mifp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './imgs/landscape_00.jpg'"
          ]
        }
      ],
      "source": [
        "with open(\"./imgs/landscape_00.jpg\", \"rb\") as ifp:\n",
        "  img_data = ifp.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EyQezLLxKph9",
        "outputId": "261c263d-7576-459b-b031-1d1b4d715c24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\" The image features a cartoon sticker of an egg character with two faces (one happy, one sad) holding a strawberry. The egg is standing next to the fruit. There's also an orange and red berry on the top right corner. \""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "client = Client(host=OLLAMA_URL)\n",
        "\n",
        "img = base64.b64encode(img_data).decode()\n",
        "\n",
        "response = client.chat(\n",
        "    model='llava',\n",
        "    messages=[{\n",
        "        'role': 'user',\n",
        "        'content': 'What is in this image? Be concise.',\n",
        "        'images': [img],\n",
        "    }]\n",
        ")\n",
        "\n",
        "# display(response)\n",
        "display(response[\"message\"][\"content\"])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}